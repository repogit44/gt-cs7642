# Project 1

### CS 7642 Spring 2018

### Dan Frakes (dfrakes3)

This file contains animated illustrations supplementary to the [Project 1 report](./project1-dfrakes3.pdf).

![random walk iteration](./out.gif)

**Example 6.2 - Random Walk. This figure shows an animation of the convergence of temporal difference learning as applied to the random walk Markov reward process example problem in _Reinforcement Learning: An Introduction_ (Sutton 1998).**

![figure 4 animated](./fig4-animated.gif)

**Animation of Figure 4 including all incremental values for $\lambda$. Each frame represents an increase to the episode length limit.**
